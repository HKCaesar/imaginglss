sharedmem
=========

sharedmem implements a MapReduce object for in core parallel execution. 
The spirit of sharedmem is similar to multiprocessing.

Here is a dumb example.

.. code::

    from model.utils import sharedmem
    import numpy

    def main():
        a = numpy.linspace(0, 1.0, 1024 * 1024)

        with sharedmem.MapReduce() as pool:
            chunksize = 1024
            def work(i):
                return numpy.sin(a[i:i+chunksize])
                
            b = numpy.concatenate(pool.map(work, range(0, len(a), chunksize)))
    
    main()

It relies on 'fork' for sharing resource between process. Functions does
not need to be picklable. The above example won't work with multiprocessing.


